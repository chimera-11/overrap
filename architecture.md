# 주의사항
이 파일은 초기 아이디어를 나타내며 최종 아이디어를 반영하지 않습니다. 이를테면 최종 버전에서 운율은 word2vec을 이용해 반영하는 대신 RNN과 rule base를 조합한 방식으로 반영합니다. 그리고 단어 사이 및 앞뒤의 빈 공간은 RNN을 이용해 채웁니다. 또한 Ending Modulation이라는 테크닉이 추가되었습니다. 이 테크닉은 운율이 맞는 가사들의 space에서 RNN이 보기에 가장 말이 되는 가사를 찾는 테크닉입니다.

# 개요
overrap은 한국어로 랩 가사를 자동 생성하는 머신러닝 프로젝트입니다.

# 아키텍처
랩 가사를 자동 생성하려면 운율에 맞게 단어를 배치하되 그 뜻에 어느 정도의 유사성이 있어야 합니다.
이러한 요건을 고려하여, overrap 아키텍처는 다음과 같은 구조로 계획하고 있습니다.
  1. 단어를 무작위로 선정합니다.
  2. 이 단어와 운율이 유사한 다른 단어를 하나 고릅니다.
  3. 두 단어를 비트에 맞게 대략 배치하고, 단어 사이 및 앞뒤의 빈 공간은 word2vec을 이용해 채웁니다.

## 단어 선정

## 운율 대구어 선정
한국어는 그 특성상 형태소 분석이 매우 용이하기 때문에 운율이 유사한 단어를 생성하기 용이합니다.
그래서 형태소 수준으로 분해해서 일일이 손으로 코딩할 수도 있습니다.
하지만 운율에는 형태소로만 설명되지는 않는 요소가 있을지도 모릅니다.
만약 그렇다면, 단어를 형태소 수준으로 분해한 뒤 그 벡터 표현을 학습하여 ("rap2vec")
유사한 단어를 끄집어내는 방식을 쓸 수 있을 것입니다. 즉, word2vec이 의미 유사성을
코사인 유사도로 매핑한다면, 우리는 운율 유사성을 코사인 유사도로 매핑하자는 것입니다.

이를 위해서는 각 단어의 벡터 표현을 학습해야 합니다. 어떻게 할까요? 한 가지 방식은
운율이 유사한 단어를 모은 집합을 구축하고, 이 집합 내의 단어들끼리는 그 벡터 표현이
비슷해지도록 신경망을 트레이닝하는 것입니다. 이를 실현하는 한 가지 방식은, 바로 신경망을
특정 단어를 받아 다른 단어들의 확률을 예측하는 방식으로 구축하는 것입니다. 이 아이디어는
word2vec에서 따온 것입니다. 중간에 정보병목을 두고(hidden layer), 다시 정보를 확장하여
단어 전체의 집합 중 해당 집합에 포함된 단어의 확률을 softmax layer로 뽑아내고,
해당 집합에 포함될 단어의 확률이 높게 나올수록 reward를 주는 것입니다. 이런 방식으로
reward function을 최대화하면 자연스럽게 그 hidden layer가 운율 관계에서 추상적 표상
(abstract representation)을 추출할 거라는 기대입니다.

물론, 한 가지 문제가 있습니다. 단어를 어떻게 벡터화해서 넣어줄 것인지의 문제인데요.
word2vec은 의미만 따지기 때문에 단어 철자와는 상관없이 one-hot encoding을 사용합니다.
하지만 우리는 그럴 수가 없습니다. 어쩌면 형태소를 벡터로 넣어주는 것이 가장 중요한 스텝일지도
모릅니다.

그러니 돌아가서, 처음부터 다시 생각해봅시다. 애초에 표기를 그대로 운율판정에 사용하는 것이 틀렸습니다.
운율판정에는 표기형태가 아니라 발음형태를 이용해야 합니다. 이를테면, 음절의 끝소리 규칙을 반영해서
끝소리가 있는 글자의 경우는 모두 ㄱ, ㄴ, ㄷ, ㄹ, ㅁ, ㅂ, ㅇ 중 하나로 바꿔주어야 합니다.
하지만 규칙은 이외에도 너무 많기 때문에, 손으로 구현하기는 어렵습니다.

이런 부분은 우리말샘 오픈 API를 활용하면 됩니다. 하루에 최대 25,000건의 요청을 보낼 수 있으니 충분할 것입니다.
https://opendict.korean.go.kr/service/openApiInfo

이렇게 해서 발음 그대로의 표현을 얻었다고 합시다. 그러면 어떻게 해야 할까요?
일단, 글자 수준에서는 대략 이런 feature encoding을 쓸 수 있을 것 같습니다.
(물론, 테스트해보고 넣거나 뺄 여지는 항상 있음)
  * 모음 특징
    * 양성 모음인가? 음성 모음인가? (모음조화)
    * 'ㅏ' 계열 발음이 있는가? (ㅏ, ㅑ, ㅒ 등)
    * 이중모음인가? (ㅑ, ㅕ, ㅛ, ㅠ, ㅖ, ㅒ 등)
    * 'ㅡ' 'ㅣ' 'ㅢ' 계열인가?
  * 자음 특징
    * 울림소리인가? (ㅁ, ㄴ, ㅇ, ㄹ)
    * 예사소리인가? 거센소리인가? 된소리인가?

그런데, 단어 단위로는 어떻게 해야 할까요? 글자수가 같으면 문제가 안 되지만, 글자수가 다른 경우는
어떻게 비교해야 공정할까요? 실제 운율이 적용되는 상황을 생각해보면, 부분적으로 일치하면 될 것
같습니다. 이를테면, '애비'와 '수제비'와 박자를 잘 맞추면 운율이 맞는 것처럼 느껴집니다.
애초에 운율이 느껴지는 이유는 아마도 바로 전에 들었던 발음과 유사한 발음이 들리기 때문일지도
모릅니다. 이런 경우는 '수제비'를 '수제'와 '제비'로 끊어서 유사성을 비교하면 될 것 같습니다.

그런데 글자수가 같다고 그 발음형태를 글자 위치대로 비교하면 충분할까요? 아마도 아닐 것입니다. 왜냐면
'X가나다'와 '가나다Y'도 유사성이 있어야 하기 때문입니다. 즉, 길이가 같은 단어라고 해서 운율 유사성이
그 위치대로 있을 필요는 없다는 점을 염두에 두어야 합니다.

그렇다면, 어떤 단어를 가져와서 운율이 맞는지 시험해 보아야 할까요? 왜냐면 모든 단어를 비교하는 것은
비효율적으로 느껴지기 때문입니다. 그런데 모든 단어를 비교하는 것이 그렇게 어려울까요? 단어 수가
10만개를 넘지 않는다면, 클럭이 GHz 단위에 이르는 요즘 컴퓨터로는 솔직히 그리 오래 걸리지 않으리라
생각이 듭니다.

물론 알고리즘이 정교해지기 시작하면 얘기가 달라집니다. 이를테면 운율이 잘 맞는 단어 쌍을
찾아라 하는 경우, 전체 단어 수의 제곱만큼 시간이 들 것입니다. 전혀 괜찮지 않습니다. 이런 경우는
미리 운율이 비슷한 단어 쌍을 어떻게든 모아두고, bounding box의 개념처럼 돌아볼 필요가 없는 것들은
배제할 필요가 있을 것입니다. 이렇게 하기 위해서는 벡터 임베딩이 필요할 수도 있습니다. 벡터 임베딩 후
공간을 공간각에 따라 수백 개의 구획으로 나누어, 특정 단어와 운율이 유사한 단어를 검색할 때는 인접한
구획에서만 검색을 하는 것이지요.


## 앞뒤 채워 완성하기
일단 word2vec이나 기타 빈칸 채우기 모델을 써서 뭐라도 돌아가게 만드는 게 일차적인 목표입니다.
word2vec은 각 단어의 벡터 표현을 학습하기 위해 hidden layer에 고의로 정보병목을 만들고,
그 정보병목을 통과해 나온 정보를 단어로 재구성할 떄 인접한 문맥의 단어가 최대한 예측될 수 있도록
매개변수를 최적화합니다. 그 기저에 깔린 아이디어는 바로 이렇게 학습된 벡터 표현이 정보병목으로 인해
핵심 정보만 담을 거라는 기대입니다.

word2vec의 개념 이해에는 Chris McCormick 아저씨의 설명이 최고입니다.

http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/
http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/

그 다음에는 좀 더 말이 되는 쪽으로, 길게 보아도 문맥이 있는 쪽으로, 만들어가는 쪽을 생각해야
합니다. 기억 관련해서 번역이나 소리 처리에 사용되는 유명한 모델로 LSTM (Long short-term memory)
이 있으니 참고해 봅시다.

사실 운율 비교판정보다는 이쪽에 딥러닝이 활용될 여지가 (얼핏 보기에는) 좀 더 커 보입니다.

## 그래프 분석
랩 가사를 쓰다 보면 때로는 기존 랩에서 잘 쓰지 않던 새로운 단어를 차용해야 할 경우가 생깁니다.
이를테면, '동해물'과 '새우'를 이용해서 랩을 만든다고 하면 의미상 '꼴뚜기'가 필요할지도 모릅니다.
이런 경우 기존 랩 가사로만 학습시킨 모델로는 구현이 어렵습니다. 따라서, 사전을 활용하는 방안을
생각해봅시다. 사전을 하나의 거대한 그래프로 생각한다면, '동해물'과 '새우'가 어딘가에는 있을 것입니다.
그러면 그래프 마이닝을 하자는 것입니다. 사전의 그래프에서 '동해물'과 '새우'에 동시에 인접한 단어들을
잘 살펴보면, 아마도 '꼴뚜기'가 있을지도 모릅니다. 운율을 잘 살펴서 적절히 사용하면 가사가 풍부해질 것입니다.

사실, 사전에 국한될 필요는 없습니다. 넓게 보면, 외부 지식베이스로의 쿼리를 허용하자는 것입니다.
네이버 국어사전을 써도 되지만, 구글 검색이나 위키백과를 써도 됩니다. 대신 이런 경우에는 단어의
문맥 연관성을 좀 더 잘 체크할 수 있는 필터가 필요할지도 모릅니다.

# 생각해볼 과제
  * 학습용 말뭉치로 무엇을 쓸 것인가?
    * 시중에 나온 랩 가사: 운율 학습에 핵심 역할
    * 기타 다른 말뭉치: 생성되는 가사 다양화, 소재 참신성 구현에 필요할 가능성
  * 학습용 말뭉치는 어떻게 확보할 것인가?
    * 음원 사이트나 가사 사이트를 크롤링하는 방법
    * 돈 주고 사는 방법
    * 노가다를 하는 방법
  * 수평 라임과 수직 라임을 어떻게 구현할 것인가?
    * 대구를 이루는 핵심어를 박아넣고, 나머지 부분을 보간하기: 간단하지만 보간이 어색할 수 있음
    * 핵심어 위치를 조정할 수 있도록 하기: 일종의 hyperparameter 개념처럼 보임
  * 곡 전체 수준에서 규칙성을 어떻게 보장할 것인가?
    * 지도학습 방식: 일반적으로 통용되는 랩 곡의 전반적인 구조를 구현해 넣고, 알고리즘이 이에 맞추도록 하기
    * 비지도학습 방식: 수많은 랩 곡을 학습해 전반적인 구조의 규칙성을 알아서 찾도록 하기
  * 랩 가사의 예술성을 어떻게 높일 것인가?
    * 별로 예술적이지 못한 랩 곡을 찾아서 넣어줄까?
    * 두 개의 랩 곡을 알려주고, 둘 중에서 어떤 스타일을 선호해야 하는지 알려줄까?
